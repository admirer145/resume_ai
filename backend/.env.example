# Model Provider Configuration
# Options: "openai" or "ollama"
MODEL_PROVIDER=ollama

# OpenAI Configuration (only needed if MODEL_PROVIDER=openai)
OPENAI_API_KEY=your_openai_api_key_here

# Ollama Configuration (only needed if MODEL_PROVIDER=ollama)
OLLAMA_BASE_URL=http://localhost:11434

# Model Selection
# For Ollama, use models you have pulled (e.g., embeddinggemma:latest, deepseek-coder:1.3b)
# For OpenAI, these are set automatically in config.py
EMBEDDING_MODEL=embeddinggemma:latest
LLM_MODEL=deepseek-coder:1.3b

# Weaviate Configuration
WEAVIATE_URL=http://localhost:8080

# Alternative Ollama Models (uncomment to use):
# Larger models for better quality (if your system supports them):
# LLM_MODEL=llama3.2:3b
# LLM_MODEL=qwen2.5:7b
# LLM_MODEL=mistral:7b
